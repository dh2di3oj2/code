{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x1         x2         x3         x0  x4         x5          x6  \\\n",
      "0  56.590866 -15.164974 -71.868156 -24952.783   1  29.327799  1122.86820   \n",
      "1  10.907610 -42.359173  -8.457231 -24962.082   1  90.882484   960.58179   \n",
      "2  34.974998  42.709808 -15.151949 -25028.438   0 -70.219116   986.54913   \n",
      "\n",
      "          x7          x8            y  \n",
      "0  -5.556481  122.028500  -74025800.0  \n",
      "1 -17.387789  -65.950005 -167792768.0  \n",
      "2  38.034069  -98.859238  136613888.0  \n",
      "               x1          x2          x3            x0          x4  \\\n",
      "count  516.000000  516.000000  516.000000    516.000000  516.000000   \n",
      "mean    51.736012   10.975219   11.932317 -25004.803167    0.525194   \n",
      "std     28.423105   33.699373   39.577027     51.363376    0.499849   \n",
      "min      0.081017  -81.257637 -134.974990 -25160.113000    0.000000   \n",
      "25%     29.936390  -12.377698  -14.996227 -25039.551500    0.000000   \n",
      "50%     51.267094   11.625733   13.688730 -25006.647500    1.000000   \n",
      "75%     77.361137   31.714382   38.983266 -24969.142000    1.000000   \n",
      "max     99.809120  114.399220  118.005890 -24807.332000    1.000000   \n",
      "\n",
      "               x5           x6          x7          x8             y  \n",
      "count  516.000000   516.000000  516.000000  516.000000  5.160000e+02  \n",
      "mean    27.319595  1001.325193    9.448520   25.045274 -5.365632e+07  \n",
      "std     80.863166    47.825841   25.628581   96.433169  1.621822e+08  \n",
      "min    -87.764595   861.280940  -79.024902 -215.919830 -4.213926e+08  \n",
      "25%    -49.464144   971.457760   -7.959556  -44.031105 -1.978516e+08  \n",
      "50%     22.316823  1003.310850   10.439490   25.376592 -4.096182e+07  \n",
      "75%     99.297767  1033.326050   26.924579   88.578406  9.906547e+07  \n",
      "max    202.022490  1122.868200   97.037865  329.430180  1.917787e+08  \n"
     ]
    }
   ],
   "source": [
    "# grab data -- change path for your own file\n",
    "df1 = pd.read_csv(\"train3.csv\")\n",
    "\n",
    "# print first few rows -- could also use df.head()\n",
    "print (df1.iloc[:3])\n",
    "# and get summary stats on variables\n",
    "print (df1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               x1          x2          x3            x0          x4  \\\n",
      "count  516.000000  516.000000  516.000000    516.000000  516.000000   \n",
      "mean    51.736012   10.975219   11.932317 -25004.803167    0.525194   \n",
      "std     28.423105   33.699373   39.577027     51.363376    0.499849   \n",
      "min      0.081017  -81.257637 -134.974990 -25160.113000    0.000000   \n",
      "25%     29.936390  -12.377698  -14.996227 -25039.551500    0.000000   \n",
      "50%     51.267094   11.625733   13.688730 -25006.647500    1.000000   \n",
      "75%     77.361137   31.714382   38.983266 -24969.142000    1.000000   \n",
      "max     99.809120  114.399220  118.005890 -24807.332000    1.000000   \n",
      "\n",
      "               x5           x6          x7          x8             y  \n",
      "count  516.000000   516.000000  516.000000  516.000000  5.160000e+02  \n",
      "mean    27.319595  1001.325193    9.448520   25.045274 -5.365632e+07  \n",
      "std     80.863166    47.825841   25.628581   96.433169  1.621822e+08  \n",
      "min    -87.764595   861.280940  -79.024902 -215.919830 -4.213926e+08  \n",
      "25%    -49.464144   971.457760   -7.959556  -44.031105 -1.978516e+08  \n",
      "50%     22.316823  1003.310850   10.439490   25.376592 -4.096182e+07  \n",
      "75%     99.297767  1033.326050   26.924579   88.578406  9.906547e+07  \n",
      "max    202.022490  1122.868200   97.037865  329.430180  1.917787e+08  \n"
     ]
    }
   ],
   "source": [
    "df2 = df1.dropna()\n",
    "# and get summary stats on variables to check to see if any variables had missingness\n",
    "print (df2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of variables to pass to PCA, x's only / exclude Y\n",
    "vars = ['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']\n",
    "x = df2.loc[:, vars].values\n",
    "\n",
    "# also create Y while we're at it for use later on in regressions\n",
    "y = df2.loc[:, 'y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize x\n",
    "x_norm = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.79315488,  0.71009618,  1.95351359, ..., -1.71580337,\n",
       "        -1.08390011,  0.43761439],\n",
       "       [ 1.59474801,  1.80638066, -1.37806176, ..., -0.26113978,\n",
       "         0.61747521,  0.35693309],\n",
       "       [-0.47591577, -1.65707858, -0.97895843, ..., -0.10299009,\n",
       "        -1.43985118,  0.33007198],\n",
       "       ...,\n",
       "       [ 0.48758674, -1.19585546,  1.00986354, ...,  2.92857389,\n",
       "        -1.43943611, -0.15287595],\n",
       "       [ 0.25343646, -1.27306849, -1.49688347, ...,  0.07264219,\n",
       "        -1.26718476, -0.30111201],\n",
       "       [ 1.81106381,  2.14263929,  1.27104288, ...,  1.56164778,\n",
       "         0.34341185,  0.4172439 ]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 8\n",
    "pca1 = PCA(n_components=dim)\n",
    "# create n dimensional representation\n",
    "latent_vars = pca1.fit_transform(x_norm)\n",
    "\n",
    "latent_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by each latent variable in PCA:  [0.25896365 0.21282259 0.12417551 0.1163428  0.10375013 0.09874006\n",
      " 0.05700854 0.01877002]\n",
      "\n",
      "\n",
      "x 0 : 0.0425 , 0.0131 , -0.4741 , 0.5572 , 0.5263 , -0.4167 , 0.1092 , 0.009 , \n",
      "\n",
      "x 1 : 0.0173 , -0.0601 , 0.0796 , 0.7421 , -0.6584 , 0.0588 , -0.0416 , 0.0014 , \n",
      "\n",
      "x 2 : -0.5766 , -0.1159 , -0.0393 , 0.0383 , 0.0602 , -0.0326 , -0.4897 , -0.6376 , \n",
      "\n",
      "x 3 : -0.5091 , -0.0929 , -0.035 , -0.0657 , -0.141 , -0.07 , 0.8211 , -0.1651 , \n",
      "\n",
      "x 4 : -0.145 , 0.6847 , 0.0727 , 0.0295 , -0.0048 , -0.0627 , -0.027 , 0.0166 , \n",
      "\n",
      "x 5 : -0.1507 , 0.6833 , 0.0633 , 0.0389 , -0.0429 , -0.0542 , -0.0009 , 0.0208 , \n",
      "\n",
      "x 6 : 0.0327 , -0.1213 , 0.6446 , -0.0155 , 0.0065 , -0.7533 , -0.0276 , 0.0122 , \n",
      "\n",
      "x 7 : -0.597 , -0.1517 , -0.0311 , 0.0198 , 0.0322 , -0.0075 , -0.2311 , 0.7515 , \n",
      "\n",
      "x 8 : -0.0707 , -0.028 , 0.5834 , 0.3606 , 0.5129 , 0.4925 , 0.1323 , -0.0235 , \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Variance explained by each latent variable in PCA: \", pca1.explained_variance_ratio_)\n",
    "print (\"\\n\")\n",
    "\n",
    "for i in range(0,9):\n",
    "    print (\"x\",i,\": \", end='')\n",
    "    for j in range(0,dim):\n",
    "        print (round(pca1.components_[j][i],4), \", \", end='')\n",
    "    print (\"\\n\")\n",
    "\n",
    "# clear from the component scores / variance explained by each dimension that x1,x2,x3 are loading on the first factor\n",
    "# also possible that x4 and x5 are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.91423837],\n",
       "       [0.91423837, 1.        ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check x4 and x5 -- only keep x5 b/c it has more variance\n",
    "np.corrcoef(df2['x4'], df2['x5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by each latent variable in PCA:  [0.75074945]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# new pca focusing on 1 factor, just using x7,x2,x3\n",
    "vars2 = ['x2', 'x3', 'x7']\n",
    "temp = df2.loc[:, vars2].values\n",
    "pca2 = PCA(n_components=1)\n",
    "\n",
    "# create 1 dimensional representation\n",
    "latent_vars = pca2.fit_transform(temp)\n",
    "\n",
    "# check to see if I'm right\n",
    "print (\"Variance explained by each latent variable in PCA: \", pca2.explained_variance_ratio_)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42.709808 -15.151949  38.034069]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      56.590866\n",
       "1      10.907610\n",
       "2      34.974998\n",
       "3      99.809120\n",
       "4      26.966738\n",
       "         ...    \n",
       "511    87.572922\n",
       "512     0.204052\n",
       "513    39.199738\n",
       "514    48.779186\n",
       "515    77.008270\n",
       "Name: x1, Length: 516, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp[2])\n",
    "df2['x1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.95775480e+01],\n",
       "       [ 5.63118401e+01],\n",
       "       [-1.19496781e+01],\n",
       "       [-5.66103121e+01],\n",
       "       [ 2.12749399e+01],\n",
       "       [-3.72835954e+01],\n",
       "       [ 1.88288594e+01],\n",
       "       [-2.42821866e+01],\n",
       "       [-3.17361468e+01],\n",
       "       [-7.82380458e+01],\n",
       "       [ 5.68533722e+01],\n",
       "       [-8.67778127e+01],\n",
       "       [-8.55255459e+00],\n",
       "       [ 6.45750333e+01],\n",
       "       [-7.51421679e+01],\n",
       "       [ 2.09166641e+01],\n",
       "       [-1.86645565e+01],\n",
       "       [ 4.54483494e+01],\n",
       "       [-4.46266870e+01],\n",
       "       [ 3.14998594e+01],\n",
       "       [ 1.59935642e+01],\n",
       "       [-1.00374143e+02],\n",
       "       [-1.28248491e+01],\n",
       "       [-4.76018216e+01],\n",
       "       [-4.21517161e+01],\n",
       "       [ 9.16236406e+00],\n",
       "       [ 5.61975673e+01],\n",
       "       [-4.37949311e+01],\n",
       "       [ 8.50246266e+01],\n",
       "       [-8.25374524e+00],\n",
       "       [-4.21629682e+01],\n",
       "       [-9.27714423e+00],\n",
       "       [ 4.76017315e+01],\n",
       "       [-1.41153239e+01],\n",
       "       [ 2.99642718e+01],\n",
       "       [ 2.84062565e+01],\n",
       "       [-4.21568791e+01],\n",
       "       [-2.28044386e+01],\n",
       "       [ 7.62210776e+00],\n",
       "       [-5.00663052e+01],\n",
       "       [-3.04549802e+01],\n",
       "       [-2.00859759e+01],\n",
       "       [ 2.09182691e+01],\n",
       "       [-1.12473298e+00],\n",
       "       [ 2.35783982e+01],\n",
       "       [ 7.00062120e+01],\n",
       "       [ 1.29975621e+02],\n",
       "       [ 6.97823266e+01],\n",
       "       [ 1.15849351e+02],\n",
       "       [ 2.65999036e+01],\n",
       "       [-5.40270471e+01],\n",
       "       [-6.76547266e+01],\n",
       "       [-3.36999547e+01],\n",
       "       [-1.10532258e+02],\n",
       "       [ 8.29553533e+01],\n",
       "       [-1.60228651e+01],\n",
       "       [-3.65375455e+01],\n",
       "       [-1.33341338e+01],\n",
       "       [-1.02291739e+02],\n",
       "       [-1.45561684e+01],\n",
       "       [-4.26252201e+01],\n",
       "       [-4.51910212e+01],\n",
       "       [ 3.10317567e+00],\n",
       "       [ 4.38905022e+01],\n",
       "       [-1.85062558e+01],\n",
       "       [-5.99573148e+01],\n",
       "       [-2.59628252e+01],\n",
       "       [ 6.11695335e+01],\n",
       "       [ 3.06602707e+01],\n",
       "       [ 6.01748097e+01],\n",
       "       [ 2.07954132e+01],\n",
       "       [ 3.84546516e+01],\n",
       "       [ 3.51562908e+01],\n",
       "       [-8.06836153e+01],\n",
       "       [ 1.16459615e+01],\n",
       "       [ 6.32481377e+01],\n",
       "       [-1.01744218e+01],\n",
       "       [-3.14350919e+01],\n",
       "       [ 5.78910418e+01],\n",
       "       [-1.93800791e+01],\n",
       "       [-3.28199875e+01],\n",
       "       [ 9.60398265e+00],\n",
       "       [-6.67730454e+01],\n",
       "       [ 4.59660646e+01],\n",
       "       [-2.81881826e+01],\n",
       "       [-2.84321043e+01],\n",
       "       [ 3.84135078e+01],\n",
       "       [-3.28931095e+01],\n",
       "       [-8.53180334e+00],\n",
       "       [-6.11274132e+00],\n",
       "       [ 1.51306830e+01],\n",
       "       [-1.72442066e+00],\n",
       "       [-4.80039411e+01],\n",
       "       [-6.31739026e+01],\n",
       "       [-6.66037685e+01],\n",
       "       [ 4.84229353e+01],\n",
       "       [-2.91901544e+01],\n",
       "       [-4.93587958e+01],\n",
       "       [ 5.57747890e+01],\n",
       "       [ 6.20176487e+01],\n",
       "       [-3.87070016e+01],\n",
       "       [-1.78163236e+01],\n",
       "       [-1.55968748e-01],\n",
       "       [-9.05969996e+01],\n",
       "       [-2.10157899e+00],\n",
       "       [ 4.53167161e+01],\n",
       "       [ 6.43550572e+00],\n",
       "       [-4.66015021e+01],\n",
       "       [-3.54341522e+01],\n",
       "       [ 2.02953445e+01],\n",
       "       [ 3.21582640e+00],\n",
       "       [-5.74358577e+01],\n",
       "       [-4.86685086e+00],\n",
       "       [ 3.67470366e+01],\n",
       "       [ 2.41189624e+01],\n",
       "       [-2.48220135e+01],\n",
       "       [ 4.92521189e+01],\n",
       "       [ 2.86765380e+00],\n",
       "       [-2.71788643e+00],\n",
       "       [ 6.64105061e+01],\n",
       "       [-6.88632547e+01],\n",
       "       [-6.27353708e-01],\n",
       "       [-3.47693281e+01],\n",
       "       [ 1.65191295e+01],\n",
       "       [ 4.61574822e+01],\n",
       "       [ 3.06849494e+01],\n",
       "       [ 3.37921674e-01],\n",
       "       [ 1.03150216e+01],\n",
       "       [ 1.07140955e+00],\n",
       "       [-1.76024702e+01],\n",
       "       [-3.79189114e+01],\n",
       "       [-4.97639636e+00],\n",
       "       [-8.81677828e+00],\n",
       "       [ 6.90885696e+01],\n",
       "       [-1.57922904e+01],\n",
       "       [ 2.49363490e+01],\n",
       "       [-9.57586841e+01],\n",
       "       [ 3.24626891e+01],\n",
       "       [ 5.20342769e+01],\n",
       "       [ 2.38549169e+01],\n",
       "       [-1.31654114e+01],\n",
       "       [ 1.33813983e+01],\n",
       "       [ 3.55833873e+01],\n",
       "       [-5.30624605e+01],\n",
       "       [ 4.21729425e+01],\n",
       "       [ 5.17055387e+01],\n",
       "       [-4.06195532e+01],\n",
       "       [ 2.25650076e+00],\n",
       "       [ 3.94844270e+00],\n",
       "       [ 2.09854045e+01],\n",
       "       [ 3.80743211e+01],\n",
       "       [ 6.12977577e+01],\n",
       "       [ 6.63552824e+01],\n",
       "       [-6.11077455e+01],\n",
       "       [-1.59624993e+01],\n",
       "       [-1.00151485e+02],\n",
       "       [-9.78069522e+00],\n",
       "       [-4.30463487e+01],\n",
       "       [-3.70694324e+01],\n",
       "       [-5.43092106e+01],\n",
       "       [-1.20839174e+02],\n",
       "       [ 3.57982839e+01],\n",
       "       [ 3.14158257e+01],\n",
       "       [ 5.41884929e+01],\n",
       "       [ 3.37097891e+01],\n",
       "       [ 8.67683023e+01],\n",
       "       [ 2.61336664e+01],\n",
       "       [-2.15746383e+00],\n",
       "       [-7.32608737e+00],\n",
       "       [ 2.83781765e+01],\n",
       "       [-5.13246156e+01],\n",
       "       [-2.29431255e+01],\n",
       "       [-1.30919657e+01],\n",
       "       [ 2.57775495e+01],\n",
       "       [-2.25921929e+01],\n",
       "       [ 1.16537542e+01],\n",
       "       [-5.16531198e+01],\n",
       "       [-2.60859796e+01],\n",
       "       [ 1.97165977e+01],\n",
       "       [-4.03524512e+01],\n",
       "       [-1.72284445e+01],\n",
       "       [-6.63535789e+01],\n",
       "       [ 3.43881553e+01],\n",
       "       [-1.83074314e+01],\n",
       "       [-4.81353746e+01],\n",
       "       [ 7.44538089e+01],\n",
       "       [-6.26509762e+01],\n",
       "       [-1.46439564e+02],\n",
       "       [-4.26101762e+01],\n",
       "       [ 6.34622011e+01],\n",
       "       [ 6.96167526e+01],\n",
       "       [ 2.03498960e+01],\n",
       "       [ 7.80737579e+00],\n",
       "       [-2.64156508e+01],\n",
       "       [ 5.75362345e+01],\n",
       "       [-2.04138322e+01],\n",
       "       [-6.84475897e+00],\n",
       "       [-4.31516221e+01],\n",
       "       [-4.34403369e+00],\n",
       "       [ 2.18550101e+01],\n",
       "       [-5.45524813e+01],\n",
       "       [ 2.44872227e+01],\n",
       "       [-5.67946689e+01],\n",
       "       [ 4.09981242e+01],\n",
       "       [ 7.28328940e+01],\n",
       "       [ 1.69962758e+01],\n",
       "       [ 2.56906414e+01],\n",
       "       [-6.22746807e+01],\n",
       "       [ 2.93535409e+00],\n",
       "       [-4.48049622e+00],\n",
       "       [ 4.01553297e+01],\n",
       "       [ 3.91593947e+01],\n",
       "       [ 4.57348052e+01],\n",
       "       [-3.39971098e+01],\n",
       "       [ 5.81849333e+01],\n",
       "       [-5.12012295e+01],\n",
       "       [ 7.51032558e+01],\n",
       "       [-1.17759664e+02],\n",
       "       [ 3.42168904e+01],\n",
       "       [ 6.57151900e+00],\n",
       "       [-4.54882849e+00],\n",
       "       [ 7.22917740e+01],\n",
       "       [ 6.41296902e+01],\n",
       "       [ 4.33347705e+01],\n",
       "       [-6.94708017e+01],\n",
       "       [-6.43897817e+01],\n",
       "       [-4.07340687e+01],\n",
       "       [-5.06280727e+01],\n",
       "       [ 1.23839631e+01],\n",
       "       [-9.79582078e-01],\n",
       "       [ 2.94914300e+00],\n",
       "       [-5.84534767e+01],\n",
       "       [ 8.17403854e+00],\n",
       "       [-3.77870501e+01],\n",
       "       [ 3.32856495e+01],\n",
       "       [-3.17047994e+01],\n",
       "       [-9.45762429e+01],\n",
       "       [-3.84224384e+00],\n",
       "       [-6.90641496e+00],\n",
       "       [-6.84105925e+01],\n",
       "       [-1.27307179e+01],\n",
       "       [-7.46027941e+01],\n",
       "       [ 1.23198232e+02],\n",
       "       [-2.84383513e+01],\n",
       "       [-2.44933209e+01],\n",
       "       [ 2.99261630e+00],\n",
       "       [ 3.23509954e+01],\n",
       "       [-3.91628206e+01],\n",
       "       [-2.15859276e+01],\n",
       "       [ 9.28750449e+01],\n",
       "       [-1.24426475e+01],\n",
       "       [-1.80648463e+01],\n",
       "       [ 4.20638935e+01],\n",
       "       [ 5.43216829e+00],\n",
       "       [-6.26601779e+01],\n",
       "       [-3.40582065e+01],\n",
       "       [ 1.63531369e+01],\n",
       "       [-5.56807019e+01],\n",
       "       [ 3.05797715e+01],\n",
       "       [-5.20122067e+01],\n",
       "       [ 1.53376873e+01],\n",
       "       [ 4.13608342e+01],\n",
       "       [ 1.33836070e+02],\n",
       "       [ 3.74591324e+00],\n",
       "       [ 2.64366160e+01],\n",
       "       [ 2.62541494e+01],\n",
       "       [ 7.76538105e+01],\n",
       "       [ 2.40984624e+01],\n",
       "       [-2.44460615e+01],\n",
       "       [ 1.81021182e+02],\n",
       "       [-2.22089783e+01],\n",
       "       [ 2.74352362e+01],\n",
       "       [ 3.05924601e+00],\n",
       "       [-1.95974091e+01],\n",
       "       [ 6.69201111e+01],\n",
       "       [-9.86110558e+00],\n",
       "       [ 1.09678976e+02],\n",
       "       [-4.02700009e+01],\n",
       "       [-3.17146728e+01],\n",
       "       [ 3.76369476e+01],\n",
       "       [-1.71212842e+01],\n",
       "       [-6.27233448e+01],\n",
       "       [-9.07383405e+01],\n",
       "       [ 5.92382418e+01],\n",
       "       [ 2.77754229e+01],\n",
       "       [-2.53455219e+01],\n",
       "       [ 8.96714194e+00],\n",
       "       [-5.01058501e+01],\n",
       "       [-5.72781476e+01],\n",
       "       [-3.09555180e+01],\n",
       "       [ 3.54302997e+01],\n",
       "       [-3.29024248e+01],\n",
       "       [-3.05243396e+01],\n",
       "       [-4.62572706e+00],\n",
       "       [-3.37331343e+01],\n",
       "       [-1.69167225e+01],\n",
       "       [-6.87698207e+01],\n",
       "       [ 5.76596906e+00],\n",
       "       [ 7.90123038e+01],\n",
       "       [ 2.14078069e+01],\n",
       "       [ 5.75590102e-01],\n",
       "       [-3.47677011e+01],\n",
       "       [-4.31274876e+00],\n",
       "       [ 2.46276843e+01],\n",
       "       [ 2.96482407e+01],\n",
       "       [ 3.59291197e+01],\n",
       "       [ 1.09030177e+01],\n",
       "       [-8.51977362e+01],\n",
       "       [-3.08389924e+01],\n",
       "       [ 1.48509593e+01],\n",
       "       [ 9.43216254e+00],\n",
       "       [ 3.64863179e+01],\n",
       "       [-1.68571022e+01],\n",
       "       [ 4.03478292e+01],\n",
       "       [-2.33950520e+01],\n",
       "       [ 3.82409408e+01],\n",
       "       [ 6.24242540e+01],\n",
       "       [-2.15396446e+01],\n",
       "       [ 5.76581778e+00],\n",
       "       [ 6.88391917e+01],\n",
       "       [ 5.84134007e+01],\n",
       "       [ 9.43509521e+01],\n",
       "       [-3.82416763e+01],\n",
       "       [-2.17220850e+01],\n",
       "       [ 6.63197408e+01],\n",
       "       [-5.63165444e+01],\n",
       "       [ 1.46498990e+01],\n",
       "       [ 5.73459283e+01],\n",
       "       [ 3.04393655e+01],\n",
       "       [ 1.06539745e+01],\n",
       "       [ 3.48039893e+01],\n",
       "       [-7.88460485e-01],\n",
       "       [-6.52542750e+01],\n",
       "       [-3.03799034e+01],\n",
       "       [-3.01067899e+01],\n",
       "       [-5.47469642e+00],\n",
       "       [-1.00515840e+02],\n",
       "       [ 2.05765245e+01],\n",
       "       [ 5.91050302e+01],\n",
       "       [-5.34125773e+01],\n",
       "       [-8.03728501e+01],\n",
       "       [-3.95646008e+01],\n",
       "       [ 1.94002640e+01],\n",
       "       [-8.91724231e-01],\n",
       "       [-6.78423772e+01],\n",
       "       [ 2.03043928e+01],\n",
       "       [ 5.56837904e+01],\n",
       "       [-8.97084730e+01],\n",
       "       [-7.56294061e+01],\n",
       "       [-2.10691138e+01],\n",
       "       [-5.54131671e+01],\n",
       "       [-1.25051718e+01],\n",
       "       [ 2.96701604e+01],\n",
       "       [-6.25758962e+01],\n",
       "       [-1.84806272e+01],\n",
       "       [-3.72291519e+00],\n",
       "       [ 1.03379579e+00],\n",
       "       [-2.10643825e+01],\n",
       "       [ 1.10291177e+02],\n",
       "       [ 5.89446686e+01],\n",
       "       [-1.06064196e+01],\n",
       "       [-6.11082286e+01],\n",
       "       [ 1.78876337e+01],\n",
       "       [ 8.77467016e+00],\n",
       "       [ 1.45526520e+01],\n",
       "       [ 1.13896616e+02],\n",
       "       [-4.80562438e+01],\n",
       "       [ 6.23258372e+01],\n",
       "       [ 1.00532778e+02],\n",
       "       [ 7.85660266e+00],\n",
       "       [-5.30556108e-01],\n",
       "       [-5.20050071e+00],\n",
       "       [ 1.95498130e+01],\n",
       "       [ 2.55322028e+01],\n",
       "       [-6.45247787e+01],\n",
       "       [-2.88105489e+01],\n",
       "       [ 5.86142641e+01],\n",
       "       [-3.83856680e+01],\n",
       "       [-4.94322660e+01],\n",
       "       [-7.21080121e+01],\n",
       "       [ 8.08766881e+00],\n",
       "       [-1.31913891e+01],\n",
       "       [ 2.46368036e+01],\n",
       "       [ 7.03722839e+01],\n",
       "       [-7.55148971e+00],\n",
       "       [-2.57773312e+01],\n",
       "       [-7.41911677e+01],\n",
       "       [-3.54552528e+01],\n",
       "       [-8.96139446e+00],\n",
       "       [-7.43281561e+01],\n",
       "       [ 9.57647215e+00],\n",
       "       [-2.22409424e+01],\n",
       "       [ 1.16520046e+01],\n",
       "       [-1.46901007e+01],\n",
       "       [-4.38803056e+01],\n",
       "       [ 1.29909465e+01],\n",
       "       [-3.24004193e+01],\n",
       "       [ 2.26128243e+01],\n",
       "       [ 1.36670803e+02],\n",
       "       [-9.11607178e+01],\n",
       "       [ 2.79924816e+01],\n",
       "       [-4.47977762e+01],\n",
       "       [-3.79928060e+01],\n",
       "       [ 7.96486259e+01],\n",
       "       [-7.46008432e+01],\n",
       "       [ 7.63009892e+01],\n",
       "       [ 6.12656940e+01],\n",
       "       [ 7.45988149e+01],\n",
       "       [-1.00849843e+02],\n",
       "       [ 2.02792357e+01],\n",
       "       [-1.52244628e+01],\n",
       "       [-9.55583164e+00],\n",
       "       [ 5.06224736e+01],\n",
       "       [-2.18978851e+01],\n",
       "       [-1.07429103e+02],\n",
       "       [ 3.47415811e+01],\n",
       "       [-1.02727918e+02],\n",
       "       [ 3.80420087e+01],\n",
       "       [-4.51941626e+01],\n",
       "       [-4.20916496e+01],\n",
       "       [ 8.67899904e+00],\n",
       "       [-1.70567396e+01],\n",
       "       [ 5.00760745e+01],\n",
       "       [ 4.39569729e+00],\n",
       "       [ 3.09131702e+00],\n",
       "       [-1.04261151e+02],\n",
       "       [ 2.26494585e+01],\n",
       "       [-3.99137923e+01],\n",
       "       [ 8.17769618e+01],\n",
       "       [ 2.58038380e+01],\n",
       "       [ 3.04256164e+01],\n",
       "       [ 3.20432508e+01],\n",
       "       [-5.87832953e+00],\n",
       "       [-8.97378329e-01],\n",
       "       [-1.76314214e+01],\n",
       "       [-6.80454601e+01],\n",
       "       [ 9.48852260e-01],\n",
       "       [-2.10173302e+01],\n",
       "       [ 3.72680761e+01],\n",
       "       [ 2.08309924e+01],\n",
       "       [ 1.01129608e+02],\n",
       "       [ 3.92598308e+01],\n",
       "       [ 2.12769764e+01],\n",
       "       [ 6.57194615e+01],\n",
       "       [-5.97718306e+00],\n",
       "       [-1.32734824e+02],\n",
       "       [ 3.10325686e+01],\n",
       "       [-1.90590221e+01],\n",
       "       [ 9.40530673e+01],\n",
       "       [ 1.15988047e+01],\n",
       "       [ 1.08021295e+02],\n",
       "       [ 7.18467286e+01],\n",
       "       [ 1.64943224e+02],\n",
       "       [ 4.96509765e+01],\n",
       "       [ 3.37198820e+01],\n",
       "       [-6.18011577e+01],\n",
       "       [-6.38459396e+01],\n",
       "       [-9.50402096e+00],\n",
       "       [ 1.01361106e+01],\n",
       "       [ 4.02072607e+00],\n",
       "       [ 5.53067730e+01],\n",
       "       [ 9.50354244e+00],\n",
       "       [-2.87871008e+01],\n",
       "       [ 5.36420052e+01],\n",
       "       [-6.37683385e+01],\n",
       "       [-7.31421333e+01],\n",
       "       [ 1.11611277e+01],\n",
       "       [-2.87927687e+01],\n",
       "       [-5.20052565e+00],\n",
       "       [ 7.61088223e+01],\n",
       "       [ 1.01636294e+02],\n",
       "       [ 5.16866741e+01],\n",
       "       [-4.06799444e+01],\n",
       "       [-4.00025561e+01],\n",
       "       [ 8.16612754e+01],\n",
       "       [ 1.12962190e+01],\n",
       "       [-1.03322611e+01],\n",
       "       [ 5.53872919e+01],\n",
       "       [ 6.56286628e+01],\n",
       "       [-1.02303816e+02],\n",
       "       [-9.31496202e-02],\n",
       "       [ 2.66010244e+01],\n",
       "       [-3.55716286e+01],\n",
       "       [ 2.36304097e+01],\n",
       "       [-5.00604527e+01],\n",
       "       [-1.30522106e+02],\n",
       "       [-6.04844857e+01],\n",
       "       [-1.60896785e+00],\n",
       "       [-1.62387993e+01],\n",
       "       [-9.69744203e+00],\n",
       "       [-1.90401244e+01],\n",
       "       [-3.29688681e+01],\n",
       "       [-3.61099393e+01],\n",
       "       [ 2.96165876e+01],\n",
       "       [-4.20820444e+01],\n",
       "       [ 7.53534693e+01],\n",
       "       [ 2.56674724e+01],\n",
       "       [-1.97388429e+01],\n",
       "       [ 6.06656521e+01],\n",
       "       [ 6.98046274e+01],\n",
       "       [-8.68754908e+01],\n",
       "       [-3.02090017e+00],\n",
       "       [ 5.59886910e+01],\n",
       "       [-4.82959609e+01],\n",
       "       [ 3.57510614e+01],\n",
       "       [ 3.23541720e+01],\n",
       "       [-7.59010184e+01],\n",
       "       [ 4.59912094e+01],\n",
       "       [ 2.83606398e+01],\n",
       "       [ 2.06954655e+01],\n",
       "       [ 5.69455825e+01],\n",
       "       [ 2.12411070e+01],\n",
       "       [ 1.26509751e+01],\n",
       "       [ 3.36570586e+01],\n",
       "       [ 7.79645076e+00],\n",
       "       [ 7.78008486e+01]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dataframe with the latent variables from pca1\n",
    "df2['pca1'] = latent_vars[:,0]\n",
    "# add the latent variables to x_norm\n",
    "x_norm = np.append(x_norm,latent_vars,1)\n",
    "latent_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is huge; reduce\n",
    "df2['y'] = df2['y']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.56664816 -0.69305938 -0.44562155]]\n",
      "[1139.57793577]\n"
     ]
    }
   ],
   "source": [
    "print(pca2.components_)\n",
    "print(pca2.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387, 6) (387,)\n",
      "(129, 6) (129,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x8</th>\n",
       "      <th>pca1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-24993.947</td>\n",
       "      <td>25.686243</td>\n",
       "      <td>-59.141308</td>\n",
       "      <td>967.46552</td>\n",
       "      <td>17.549107</td>\n",
       "      <td>-3.842244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-24977.256</td>\n",
       "      <td>40.742981</td>\n",
       "      <td>52.727146</td>\n",
       "      <td>970.91107</td>\n",
       "      <td>168.168290</td>\n",
       "      <td>77.653810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-25046.371</td>\n",
       "      <td>43.734684</td>\n",
       "      <td>58.652260</td>\n",
       "      <td>1059.24330</td>\n",
       "      <td>173.419100</td>\n",
       "      <td>35.798284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-25118.951</td>\n",
       "      <td>31.821974</td>\n",
       "      <td>107.135050</td>\n",
       "      <td>1012.04820</td>\n",
       "      <td>76.147202</td>\n",
       "      <td>8.967142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-25058.877</td>\n",
       "      <td>43.051487</td>\n",
       "      <td>93.930611</td>\n",
       "      <td>1046.27700</td>\n",
       "      <td>91.226517</td>\n",
       "      <td>-45.191021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-25010.123</td>\n",
       "      <td>17.328974</td>\n",
       "      <td>95.422188</td>\n",
       "      <td>1012.14370</td>\n",
       "      <td>76.029076</td>\n",
       "      <td>-94.576243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-25056.314</td>\n",
       "      <td>92.899544</td>\n",
       "      <td>69.173409</td>\n",
       "      <td>1019.51030</td>\n",
       "      <td>26.565176</td>\n",
       "      <td>-61.107745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-25013.008</td>\n",
       "      <td>59.304676</td>\n",
       "      <td>-43.168617</td>\n",
       "      <td>1019.89010</td>\n",
       "      <td>120.696750</td>\n",
       "      <td>11.645961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-24983.088</td>\n",
       "      <td>79.907486</td>\n",
       "      <td>48.484451</td>\n",
       "      <td>974.23834</td>\n",
       "      <td>-109.069070</td>\n",
       "      <td>-51.653120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-25001.063</td>\n",
       "      <td>51.714844</td>\n",
       "      <td>-41.883160</td>\n",
       "      <td>1043.96850</td>\n",
       "      <td>-70.416672</td>\n",
       "      <td>59.105030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0         x1          x5          x6          x8       pca1\n",
       "237 -24993.947  25.686243  -59.141308   967.46552   17.549107  -3.842244\n",
       "266 -24977.256  40.742981   52.727146   970.91107  168.168290  77.653810\n",
       "161 -25046.371  43.734684   58.652260  1059.24330  173.419100  35.798284\n",
       "286 -25118.951  31.821974  107.135050  1012.04820   76.147202   8.967142\n",
       "61  -25058.877  43.051487   93.930611  1046.27700   91.226517 -45.191021\n",
       "..         ...        ...         ...         ...         ...        ...\n",
       "236 -25010.123  17.328974   95.422188  1012.14370   76.029076 -94.576243\n",
       "153 -25056.314  92.899544   69.173409  1019.51030   26.565176 -61.107745\n",
       "74  -25013.008  59.304676  -43.168617  1019.89010  120.696750  11.645961\n",
       "176 -24983.088  79.907486   48.484451   974.23834 -109.069070 -51.653120\n",
       "338 -25001.063  51.714844  -41.883160  1043.96850  -70.416672  59.105030\n",
       "\n",
       "[387 rows x 6 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IVs = ['x0', 'x1', 'x5', 'x6', 'x8', 'pca1']\n",
    "\n",
    "# create train / test split using dataframe\n",
    "x_train, x_test, y_train, y_test = train_test_split(df2.loc[:, IVs], df2.loc[:, 'y'], test_size=0.25, random_state=13)\n",
    "\n",
    "# make sure results make sense\n",
    "print (x_train.shape, y_train.shape)\n",
    "print (x_test.shape, y_test.shape)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# try both linear and polynomial of different degrees\n",
    "linear_model = LinearRegression(normalize=True)\n",
    "p2_model = LinearRegression(normalize=True)\n",
    "p3_model = LinearRegression(normalize=True)\n",
    "\n",
    "# create polynomial features\n",
    "p2_features = PolynomialFeatures(degree=2)\n",
    "p2_train = p2_features.fit_transform(x_train)\n",
    "p2_test = p2_features.fit_transform(x_test)\n",
    "\n",
    "p3_features = PolynomialFeatures(degree=3)\n",
    "p3_train = p3_features.fit_transform(x_train)\n",
    "p3_test = p3_features.fit_transform(x_test)\n",
    "\n",
    "# now do estimation of models\n",
    "lin_1 = linear_model.fit(x_train, y_train)\n",
    "p2_1 = p2_model.fit(p2_train, y_train)\n",
    "p3_1 = p3_model.fit(p3_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.52317969e-01  4.44402790e+00 -2.00688087e+03 -1.56112175e+02\n",
      " -9.63162596e+00 -1.83669692e+00]\n",
      "[ 1.77066567e+17 -7.01545455e+01  6.79793587e+02  2.18066077e+03\n",
      "  3.10579275e+02 -1.57074062e+02  5.99028193e+00 -1.31425445e-03\n",
      "  2.57727370e-02  6.66971347e-03  3.49860706e-03 -7.07677695e-03\n",
      "  1.53502432e-04 -6.09931957e-02 -2.65217721e-02 -2.95764351e-02\n",
      "  4.45034888e-02  4.94422080e-02 -9.90855677e-03 -4.01596925e+00\n",
      "  4.88640822e-03  5.98087775e-03 -1.09460274e-01 -2.21003401e-02\n",
      " -5.05066210e-03  1.37457467e-03  1.31429557e-03  5.71950523e-04]\n",
      "-1.7706656687834848e+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'x0',\n",
       " 'x1',\n",
       " 'x2',\n",
       " 'x3',\n",
       " 'x4',\n",
       " 'x5',\n",
       " 'x0^2',\n",
       " 'x0 x1',\n",
       " 'x0 x2',\n",
       " 'x0 x3',\n",
       " 'x0 x4',\n",
       " 'x0 x5',\n",
       " 'x1^2',\n",
       " 'x1 x2',\n",
       " 'x1 x3',\n",
       " 'x1 x4',\n",
       " 'x1 x5',\n",
       " 'x2^2',\n",
       " 'x2 x3',\n",
       " 'x2 x4',\n",
       " 'x2 x5',\n",
       " 'x3^2',\n",
       " 'x3 x4',\n",
       " 'x3 x5',\n",
       " 'x4^2',\n",
       " 'x4 x5',\n",
       " 'x5^2']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lin_1.coef_)\n",
    "\n",
    "print(p2_1.coef_)\n",
    "print(p2_1.intercept_)\n",
    "p2_features.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict values for test sets\n",
    "lin1_predict = lin_1.predict(x_test)\n",
    "p2_predict = p2_1.predict(p2_test)\n",
    "p3_predict = p3_1.predict(p3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38719.7983378  109529.50031567 -28002.02115934 -77697.12504772\n",
      " 106530.55153601  68089.23728347 -52943.11560141 -25943.35720998\n",
      " 101476.45262714 137717.85191282]\n",
      "151     52607.792\n",
      "341     89044.552\n",
      "29     -28404.036\n",
      "0      -74025.800\n",
      "504     94448.432\n",
      "215     84948.224\n",
      "58     -54579.260\n",
      "71     -35814.480\n",
      "65      87980.104\n",
      "223    170827.376\n",
      "Name: y, dtype: float64\n",
      "\n",
      "\n",
      "151    13887.993662\n",
      "341   -20484.948316\n",
      "29      -402.014841\n",
      "0       3671.325048\n",
      "504   -12082.119536\n",
      "215    16858.986717\n",
      "58     -1636.144399\n",
      "71     -9871.122790\n",
      "65    -13496.348627\n",
      "223    33109.524087\n",
      "Name: y, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of errors')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IVs = ['x0', 'x1', 'x5', 'x6', 'x8', 'pca1']\n",
    "\n",
    "# create train / test split using dataframe\n",
    "x_train, x_test, y_train, y_test = train_test_split(df2.loc[:, IVs], df2.loc[:, 'y'], test_size=0.25, random_state=13)\n",
    "\n",
    "# try both linear and polynomial of different degrees\n",
    "linear_model = LinearRegression(normalize=True)\n",
    "\n",
    "# now do estimation of models\n",
    "lin_1 = linear_model.fit(x_train, y_train)\n",
    "\n",
    "# ok, check first ten observations of predictions, y_test, and errors to make sure nothing is wrong\n",
    "print (lin1_predict[0:10])\n",
    "print (y_test[0:10])\n",
    "\n",
    "# this creates errors of y and y'\n",
    "errors = (y_test - lin1_predict)\n",
    "print()\n",
    "print()\n",
    "print (errors[0:10])\n",
    "\n",
    "# do histogram -- choose reasonable bins parameter\n",
    "errors.hist(bins = 40)\n",
    "plt.title('Histogram of errors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "28\n",
      "84\n",
      "[ 2.52317969e-01  4.44402790e+00 -2.00688087e+03 -1.56112175e+02\n",
      " -9.63162596e+00 -1.83669692e+00]\n",
      "163819.70739434802\n",
      "Index(['x0', 'x1', 'x5', 'x6', 'x8', 'pca1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# just check that things make sense\n",
    "print (len(lin_1.coef_))\n",
    "print (len(p2_1.coef_))\n",
    "print (len(p3_1.coef_))\n",
    "print (lin_1.coef_)\n",
    "print (lin_1.intercept_)\n",
    "print (x_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98829708 0.99031867 0.98946065 0.99160136 0.99391446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# one can do this w/ cross_val_score or kfold -- but this is easier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(linear_model, df2.loc[:, IVs], df2.loc[:, 'y'], cv=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear train / test rmse:  15293.818047282764  /  15702.238713293505\n",
      "poly degree 2 train / test rmse:  459.6414498467199  /  683.8298801325353\n",
      "poly degree 3 train / test rmse:  0.011811952447477216  /  0.0154062438551843\n",
      "linear train / test r^2:  0.9912661983730524  /  0.9900007291093141\n",
      "poly degree 2 train / test r^2:  0.9999921112197746  /  0.9999810355029193\n",
      "poly degree 3 train / test r^2:  0.9999999999999948  /  0.9999999999999903\n"
     ]
    }
   ],
   "source": [
    "# find RMSE; y_true first then y_model\n",
    "print (\"linear train / test rmse: \", mean_squared_error(y_train, lin_1.predict(x_train))**(.5), \" / \", mean_squared_error(y_test, lin1_predict)**(.5))\n",
    "print (\"poly degree 2 train / test rmse: \", mean_squared_error(y_train, p2_1.predict(p2_train))**(.5), \" / \", mean_squared_error(y_test, p2_predict)**(.5))\n",
    "print (\"poly degree 3 train / test rmse: \", mean_squared_error(y_train, p3_1.predict(p3_train))**(.5), \" / \", mean_squared_error(y_test, p3_predict)**(.5))\n",
    "\n",
    "# also do R^2\n",
    "print (\"linear train / test r^2: \", r2_score(y_train, lin_1.predict(x_train)), \" / \", r2_score(y_test, lin1_predict))\n",
    "print (\"poly degree 2 train / test r^2: \", r2_score(y_train, p2_1.predict(p2_train)), \" / \", r2_score(y_test, p2_predict))\n",
    "print (\"poly degree 3 train / test r^2: \", r2_score(y_train, p3_1.predict(p3_train)), \" / \", r2_score(y_test, p3_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 ,  0.25231796881262597\n",
      "x1 ,  4.444027898301708\n",
      "x5 ,  -2006.8808674570814\n",
      "x6 ,  -156.1121749672573\n",
      "x8 ,  -9.631625955460963\n",
      "pca1 ,  -1.8366969212284396\n"
     ]
    }
   ],
   "source": [
    "# now, look for large magnitude IVs -- note trick with get_features_names() to have columns from original data\n",
    "for i in range(0, len(IVs)):\n",
    "    print (IVs[i], \", \", (lin_1.coef_)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ,  1.770665668773024e+17\n",
      "x0 ,  -70.15454554682633\n",
      "x1 ,  679.7935872871417\n",
      "x5 ,  2180.6607697061045\n",
      "x6 ,  310.5792749369337\n",
      "x8 ,  -157.07406226574037\n",
      "pca1 ,  5.990281932053079\n",
      "x0^2 ,  -0.0013142544454173724\n",
      "x0 x1 ,  0.025772737014114665\n",
      "x0 x5 ,  0.006669713471876375\n",
      "x0 x6 ,  0.0034986070581186743\n",
      "x0 x8 ,  -0.007076776950025979\n",
      "x0 pca1 ,  0.00015350243237769056\n",
      "x1^2 ,  -0.06099319567349643\n",
      "x1 x5 ,  -0.026521772149262424\n",
      "x1 x6 ,  -0.029576435098393472\n",
      "x1 x8 ,  0.04450348877357197\n",
      "x1 pca1 ,  0.04944220802549821\n",
      "x5^2 ,  -0.009908556771725655\n",
      "x5 x6 ,  -4.015969245277672\n",
      "x5 x8 ,  0.004886408219771216\n",
      "x5 pca1 ,  0.005980877752885765\n",
      "x6^2 ,  -0.10946027387213436\n",
      "x6 x8 ,  -0.022100340108417167\n",
      "x6 pca1 ,  -0.005050662099190554\n",
      "x8^2 ,  0.0013745746700007352\n",
      "x8 pca1 ,  0.0013142955738378807\n",
      "pca1^2 ,  0.0005719505225296168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# now, look for large magnitude IVs -- note trick with get_features_names() to have columns from original data\n",
    "for i in range(0, len(p2_features.get_feature_names())):\n",
    "    print (p2_features.get_feature_names(x_train.columns)[i], \", \", (p2_1.coef_)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ,  -3.0634781444786533e-07\n",
      "x0 ,  2.5101941176701965\n",
      "x1 ,  -4.113040068639729\n",
      "x5 ,  -0.683540774467103\n",
      "x6 ,  -2.919782993167504\n",
      "x8 ,  -1.6507639305496942\n",
      "pca1 ,  3.1423969073292426\n",
      "x0^2 ,  9.541412674076859e-05\n",
      "x0 x1 ,  -0.0003156816943890046\n",
      "x0 x5 ,  -5.326563373831564e-05\n",
      "x0 x6 ,  -0.0002053801815024607\n",
      "x0 x8 ,  -0.00012664675024010792\n",
      "x0 pca1 ,  0.00026309150521947337\n",
      "x1^2 ,  0.000767363260351366\n",
      "x1 x5 ,  -0.00024223430883108993\n",
      "x1 x6 ,  0.0003385993926901369\n",
      "x1 x8 ,  0.0003477031200588537\n",
      "x1 pca1 ,  0.0002691429671203643\n",
      "x5^2 ,  -1.7814512942955003e-05\n",
      "x5 x6 ,  1.5351066918062318e-05\n",
      "x5 x8 ,  9.331121238101866e-05\n",
      "x5 pca1 ,  0.00021517466316245385\n",
      "x6^2 ,  0.0003409587842134874\n",
      "x6 x8 ,  0.0001109287847292056\n",
      "x6 pca1 ,  0.0002715529089086467\n",
      "x8^2 ,  -3.082342959129173e-05\n",
      "x8 pca1 ,  0.00024915271063597117\n",
      "pca1^2 ,  0.00047922715148201035\n",
      "x0^3 ,  1.2147566691543781e-09\n",
      "x0^2 x1 ,  -6.056221471737651e-09\n",
      "x0^2 x5 ,  -1.0640959887957086e-09\n",
      "x0^2 x6 ,  -3.5604376331987787e-09\n",
      "x0^2 x8 ,  -2.4252672023820673e-09\n",
      "x0^2 pca1 ,  5.491926174598109e-09\n",
      "x0 x1^2 ,  -8.77771997062898e-09\n",
      "x0 x1 x5 ,  -9.721066048715093e-09\n",
      "x0 x1 x6 ,  1.3013611122779214e-08\n",
      "x0 x1 x8 ,  1.307830173395538e-08\n",
      "x0 x1 pca1 ,  1.2821642237015602e-08\n",
      "x0 x5^2 ,  -6.07373539513873e-10\n",
      "x0 x5 x6 ,  4.465428591857446e-10\n",
      "x0 x5 x8 ,  3.913882126901469e-09\n",
      "x0 x5 pca1 ,  8.589632282499148e-09\n",
      "x0 x6^2 ,  1.3183913174310465e-08\n",
      "x0 x6 x8 ,  4.4546034678032025e-09\n",
      "x0 x6 pca1 ,  1.0566984366256475e-08\n",
      "x0 x8^2 ,  -1.2105549271709993e-09\n",
      "x0 x8 pca1 ,  1.0446682455214526e-08\n",
      "x0 pca1^2 ,  1.928297547055536e-08\n",
      "x1^3 ,  -2.4420502545104534e-08\n",
      "x1^2 x5 ,  7.509434198080487e-09\n",
      "x1^2 x6 ,  1.637745955333048e-08\n",
      "x1^2 x8 ,  -4.524902994017207e-09\n",
      "x1^2 pca1 ,  -2.8623567431362397e-08\n",
      "x1 x5^2 ,  8.734805071142765e-09\n",
      "x1 x5 x6 ,  -2.1298831509586186e-09\n",
      "x1 x5 x8 ,  -6.431121620565128e-09\n",
      "x1 x5 pca1 ,  1.3917173619495319e-08\n",
      "x1 x6^2 ,  -7.266956807951723e-09\n",
      "x1 x6 x8 ,  -2.0571769239066655e-08\n",
      "x1 x6 pca1 ,  5.337331658766573e-08\n",
      "x1 x8^2 ,  -1.411869952245494e-10\n",
      "x1 x8 pca1 ,  -1.972283067132394e-11\n",
      "x1 pca1^2 ,  3.769366507723562e-09\n",
      "x5^3 ,  -1.7352512379409367e-09\n",
      "x5^2 x6 ,  2.2458545227020946e-09\n",
      "x5^2 x8 ,  3.943183955379035e-09\n",
      "x5^2 pca1 ,  -8.221986801621772e-09\n",
      "x5 x6^2 ,  -0.002000002156100439\n",
      "x5 x6 x8 ,  4.8543985041061565e-09\n",
      "x5 x6 pca1 ,  -3.2936170463477353e-10\n",
      "x5 x8^2 ,  -1.1944586173385444e-09\n",
      "x5 x8 pca1 ,  -1.1761814991144962e-09\n",
      "x5 pca1^2 ,  -2.2940111583325154e-09\n",
      "x6^3 ,  -3.7244750174513503e-09\n",
      "x6^2 x8 ,  8.300339072348248e-10\n",
      "x6^2 pca1 ,  -4.999050768473728e-09\n",
      "x6 x8^2 ,  5.893909005668832e-10\n",
      "x6 x8 pca1 ,  1.189714830301629e-08\n",
      "x6 pca1^2 ,  2.9274039246870756e-09\n",
      "x8^3 ,  -7.435090189178575e-10\n",
      "x8^2 pca1 ,  9.085497451242969e-10\n",
      "x8 pca1^2 ,  8.450640339573879e-11\n",
      "pca1^3 ,  -6.049579666736729e-10\n"
     ]
    }
   ],
   "source": [
    "# now, look for large magnitude IVs -- note trick with get_features_names() to have columns from original data\n",
    "for i in range(0, len(p3_features.get_feature_names())):\n",
    "    print (p3_features.get_feature_names(x_train.columns)[i], \", \", (p3_1.coef_)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345.63875611959577\n",
      "345.67557594567916\n",
      "345.7199922013434\n",
      "345.7544843595977\n",
      "345.6970826711777\n",
      "345.895399688363\n",
      "346.2301102978398\n",
      "348.7822530563021\n",
      "364.9235222118579\n",
      "394.37248368110954\n",
      "373.19956707488797\n"
     ]
    }
   ],
   "source": [
    "# lots of variables, but many are small -- time to use regularized regression to get rid of some\n",
    "# try lasso and test different penalties\n",
    "lambdas = (.1, .5, 1, 2.5, 5, 7.5, 10, 20, 50, 100, 200)\n",
    "\n",
    "for i in lambdas:    \n",
    "    lasso_reg = Lasso(alpha = i, max_iter=10000)\n",
    "    lasso1 = lasso_reg.fit(p3_train, y_train)\n",
    "    lasso1_predict = lasso1.predict(p3_test)\n",
    "    print (mean_squared_error(y_test, lasso1_predict)**(.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345.6970826711777\n"
     ]
    }
   ],
   "source": [
    "# ok, go for higher value of lambda given the above\n",
    "lasso_reg = Lasso(alpha = 5, max_iter=10000)\n",
    "lasso1 = lasso_reg.fit(p3_train, y_train)\n",
    "lasso1_predict = lasso1.predict(p3_test)\n",
    "print (mean_squared_error(y_test, lasso1_predict)**(.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ,  0.0\n",
      "x0 ,  7.233384834708834\n",
      "x1 ,  -0.0\n",
      "x5 ,  71.33895454354587\n",
      "x6 ,  22.711273339398257\n",
      "x8 ,  -3.968088413810939\n",
      "pca1 ,  0.0\n",
      "x0^2 ,  -0.00020036726748786537\n",
      "x0 x1 ,  -0.0018792893905536275\n",
      "x0 x5 ,  0.0012953938250614815\n",
      "x0 x6 ,  -0.000298933377186323\n",
      "x0 x8 ,  2.5469338703918227e-05\n",
      "x0 pca1 ,  0.00024787760086999376\n",
      "x1^2 ,  -0.028747620666669298\n",
      "x1 x5 ,  0.10619887692951561\n",
      "x1 x6 ,  0.029573525260674256\n",
      "x1 x8 ,  -0.10758358631320945\n",
      "x1 pca1 ,  0.19955031155760652\n",
      "x5^2 ,  -0.0053903090901936835\n",
      "x5 x6 ,  -0.9903897834563457\n",
      "x5 x8 ,  0.072318346078702\n",
      "x5 pca1 ,  0.24675884004255172\n",
      "x6^2 ,  -0.027250239106255587\n",
      "x6 x8 ,  -0.0013882590938546692\n",
      "x6 pca1 ,  -0.01793667722321476\n",
      "x8^2 ,  -0.022100456252538606\n",
      "x8 pca1 ,  -0.159162571189998\n",
      "pca1^2 ,  0.22175774055088232\n",
      "x0^3 ,  -5.660468385347051e-09\n",
      "x0^2 x1 ,  -2.1521673497767068e-07\n",
      "x0^2 x5 ,  1.5020355905479047e-06\n",
      "x0^2 x6 ,  1.299866595680502e-07\n",
      "x0^2 x8 ,  2.403020894695889e-08\n",
      "x0^2 pca1 ,  5.319544023755408e-09\n",
      "x0 x1^2 ,  -3.8946395158407294e-05\n",
      "x0 x1 x5 ,  -5.288875001081845e-06\n",
      "x0 x1 x6 ,  -1.2705269181399033e-06\n",
      "x0 x1 x8 ,  2.5495760568888362e-06\n",
      "x0 x1 pca1 ,  -5.122018926445655e-06\n",
      "x0 x5^2 ,  2.65377952284943e-06\n",
      "x0 x5 x6 ,  3.9203066434961824e-05\n",
      "x0 x5 x8 ,  -4.197538231406281e-07\n",
      "x0 x5 pca1 ,  2.9926515816573833e-06\n",
      "x0 x6^2 ,  1.1491456833969965e-06\n",
      "x0 x6 x8 ,  1.4747736502352061e-07\n",
      "x0 x6 pca1 ,  2.678912639267203e-07\n",
      "x0 x8^2 ,  -2.2205341775631864e-07\n",
      "x0 x8 pca1 ,  -1.0296264276141147e-06\n",
      "x0 pca1^2 ,  2.6645001320327543e-08\n",
      "x1^3 ,  0.0007021586702284444\n",
      "x1^2 x5 ,  0.00012647880617293653\n",
      "x1^2 x6 ,  -0.0010665708914806536\n",
      "x1^2 x8 ,  -0.00015544934618244146\n",
      "x1^2 pca1 ,  0.00091663574531947\n",
      "x1 x5^2 ,  -0.00016012742755614523\n",
      "x1 x5 x6 ,  -0.0002425548075645747\n",
      "x1 x5 x8 ,  3.907734764653469e-05\n",
      "x1 x5 pca1 ,  -0.00014509943483574243\n",
      "x1 x6^2 ,  3.260129630266823e-05\n",
      "x1 x6 x8 ,  0.0001950064239605101\n",
      "x1 x6 pca1 ,  -0.0004099518447833406\n",
      "x1 x8^2 ,  -4.207656163115128e-05\n",
      "x1 x8 pca1 ,  -0.00028127384992381494\n",
      "x1 pca1^2 ,  -7.870688644210356e-05\n",
      "x5^3 ,  2.357265582409928e-06\n",
      "x5^2 x6 ,  7.06763363007345e-05\n",
      "x5^2 x8 ,  5.38221833463509e-05\n",
      "x5^2 pca1 ,  -1.8108390312463363e-05\n",
      "x5 x6^2 ,  -0.001008719468468242\n",
      "x5 x6 x8 ,  -8.821763791735013e-05\n",
      "x5 x6 pca1 ,  -0.00015804156229779734\n",
      "x5 x8^2 ,  -6.798182529196715e-06\n",
      "x5 x8 pca1 ,  -6.817016423977124e-05\n",
      "x5 pca1^2 ,  -8.705053650267379e-05\n",
      "x6^3 ,  -5.210494479463749e-07\n",
      "x6^2 x8 ,  -5.84938895609642e-06\n",
      "x6^2 pca1 ,  2.88725927195279e-05\n",
      "x6 x8^2 ,  2.0873918127994013e-05\n",
      "x6 x8 pca1 ,  0.00015264876276350705\n",
      "x6 pca1^2 ,  -0.00021362518111472082\n",
      "x8^3 ,  -1.6946854474108118e-05\n",
      "x8^2 pca1 ,  -9.479894117770752e-06\n",
      "x8 pca1^2 ,  -1.3473049924754158e-05\n",
      "pca1^3 ,  -8.021882697867233e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# now, look for large magnitude IVs -- note trick with get_features_names() to have columns from original data\n",
    "for i in range(0, len(p3_features.get_feature_names())):\n",
    "    print (p3_features.get_feature_names(x_train.columns)[i], \", \", (lasso1.coef_)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above, clear that x5, x6 are the largest IV's, followed by x0 and x8; pca1 has a modest effect, some interaction of x5*x6, x7^2, and that's about it.  \n",
    "# So rerun with those and call it a day.  \n",
    "# one issue: the above only has 2nd order polys / interactions, but the above results show that the degree 3 poly did better OOS\n",
    "# either I've missed a term, or there's a bug somewhere above -- that said, this isn't quite enough data to get stable results\n",
    "# if one changes the random number seed or the proportion or train / test, things change more than I'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
