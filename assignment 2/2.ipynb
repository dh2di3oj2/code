{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                  l_names l_team18 l_pos18  l_gp18  l_points18  draft_pick  \\\n",
       "0         Brandon LaFell      Oak      WR       6   46.000000         NaN   \n",
       "1        Lance Kendricks       NE      TE      16   47.330002         NaN   \n",
       "2           Cody Kessler      Phi      QB       5   47.660000         NaN   \n",
       "3    James O'Shaughnessy      Jax      TE      14   48.270000         NaN   \n",
       "4         D.J. Chark Jr.      Jax      WR      11   48.400002         NaN   \n",
       "..                   ...      ...     ...     ...         ...         ...   \n",
       "166      DeAndre Hopkins      Hou      WR      16  384.100010        31.0   \n",
       "167      Ezekiel Elliott      Dal      RB      15  400.200010         1.0   \n",
       "168         Alvin Kamara       NO      RB      15  419.370000        38.0   \n",
       "169       Todd Gurley II      LAR      RB      14  422.769990         7.0   \n",
       "170       Saquon Barkley      NYG      RB      16  427.769990        15.0   \n",
       "\n",
       "     cost l_team17 l_pos17  l_gp17  ...  pick17  cost17  off_linefo18  \\\n",
       "0     NaN      Cin      WR    16.0  ...   228.0     2.0            13   \n",
       "1     NaN       GB      TE    16.0  ...     NaN     NaN             3   \n",
       "2     NaN      NaN     NaN     NaN  ...     NaN     NaN            19   \n",
       "3     NaN      NaN     NaN     NaN  ...     NaN     NaN            21   \n",
       "4     NaN      NaN     NaN     NaN  ...     NaN     NaN            21   \n",
       "..    ...      ...     ...     ...  ...     ...     ...           ...   \n",
       "166  52.0      Hou      WR    15.0  ...   119.0    30.0            27   \n",
       "167  54.0      Dal      RB    10.0  ...    19.0    36.0             8   \n",
       "168  58.0       NO      RB    16.0  ...   214.0     1.0             2   \n",
       "169  67.0      LAR      RB    15.0  ...    51.0    40.0             1   \n",
       "170  54.0      NYG      RB     NaN  ...     NaN     NaN            29   \n",
       "\n",
       "     off_linepff18  off_passydsg17  off_runydsg17  off_ptsg17  def_ydsg17  \\\n",
       "0                7       226.89999      97.099998   18.799999   350.10001   \n",
       "1               11       276.10001     118.100000   28.600000   366.00000   \n",
       "2                1       233.60001     132.200000   28.600000   306.50000   \n",
       "3               15       224.60001     141.399990   26.100000   286.10001   \n",
       "4               15       224.60001     141.399990   26.100000   286.10001   \n",
       "..             ...             ...            ...         ...         ...   \n",
       "166             32       204.89999     115.100000   21.100000   346.60001   \n",
       "167              2       196.30000     135.600010   22.100000   318.10001   \n",
       "168              6       261.79999     129.399990   28.000000   336.50000   \n",
       "169             10       239.39999     122.100000   29.900000   339.60001   \n",
       "170             25       217.39999      96.800003   15.400000   373.20001   \n",
       "\n",
       "     def_ptsg17     train  \n",
       "0     23.299999  0.868933  \n",
       "1     18.500000  0.555103  \n",
       "2     18.400000  0.875991  \n",
       "3     16.799999  0.892759  \n",
       "4     16.799999  0.584466  \n",
       "..          ...       ...  \n",
       "166   27.299999  0.667398  \n",
       "167   20.799999  0.629151  \n",
       "168   20.400000  0.532902  \n",
       "169   20.600000  0.727590  \n",
       "170   24.299999  0.635873  \n",
       "\n",
       "[171 rows x 38 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train75.csv')\n",
    "df.info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['cost','cost17','draft_pick','l_owners17','pick17','train','l_2pt17'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wr = df[df.l_pos18 == \"WR\"]\n",
    "df_rb = df[df.l_pos18 == \"RB\"]\n",
    "df_qb = df[df.l_pos18 == \"QB\"]\n",
    "df_te = df[df.l_pos18 == \"TE\"]\n",
    "\n",
    "df_wrte = pd.concat([df_wr, df_te])\n",
    "\n",
    "\n",
    "\n",
    "df_wrte=df_wrte.dropna()\n",
    "df_rb=df_rb.dropna()\n",
    "df_qb=df_qb.dropna()\n",
    "df_te=df_te.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of variables to pass to PCA, x's only / exclude Y\n",
    "vars = ['l_points17','l_gp17','l_actual17','l_passyds17','l_passtd17','l_passint17','l_rushyds17','l_rushtd17','l_rush1st17','l_recepts17','l_recyds17','l_rectd17','l_rec1st17','l_returnyds17','l_returntd17','l_fumble17','off_passydsg17','off_runydsg17']\n",
    "x_wrte = df_wrte[vars]\n",
    "y_wrte = df_wrte[['l_points18']]\n",
    "\n",
    "x_qb = df_qb[vars]\n",
    "y_qb = df_qb[['l_points18']]\n",
    "\n",
    "x_rb = df_rb[vars]\n",
    "y_rb = df_rb[['l_points18']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40., 38., 26., 20., 15.,  9.,  7.,  7.,  5.,  4.]),\n",
       " array([ 46.      ,  84.176999, 122.353998, 160.530997, 198.707996,\n",
       "        236.884995, 275.061994, 313.238993, 351.415992, 389.592991,\n",
       "        427.76999 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.l_points18) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.3364918888889\n",
      "133.47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame._add_numeric_operations.<locals>.std of 0       46.000000\n",
       "1       47.330002\n",
       "2       47.660000\n",
       "3       48.270000\n",
       "4       48.400002\n",
       "          ...    \n",
       "166    384.100010\n",
       "167    400.200010\n",
       "168    419.370000\n",
       "169    422.769990\n",
       "170    427.769990\n",
       "Name: l_points18, Length: 171, dtype: float64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.l_points18.mean())\n",
    "print(df.l_points18.median())\n",
    "df.l_points18.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wrte_norm = StandardScaler().fit_transform(x_wrte)\n",
    "x_qb_norm = StandardScaler().fit_transform(x_qb)\n",
    "x_rb_norm = StandardScaler().fit_transform(x_rb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numPCA(x,v):\n",
    "    pca = PCA(.90)\n",
    "    model = pca.fit(StandardScaler().fit_transform(x[v]))\n",
    "    n_pcs = pca.n_components_\n",
    "        # LIST COMPREHENSION HERE\n",
    "    most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "    #print(model.components_)\n",
    "    initial_feature_names = v\n",
    "    # get the names\n",
    "    most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "    # LIST COMPREHENSION HERE AGAIN\n",
    "    dic = {'PC{}'.format(i): most_important_names[i] for i in range(n_pcs)}\n",
    "\n",
    "    # build the dataframe\n",
    "    df2 = pd.DataFrame(dic.items())\n",
    "    print (n_pcs)\n",
    "    print (pca.explained_variance_ratio_)\n",
    "    #print(df2)\n",
    "    return  df2\n",
    "\n",
    "vpass =[]\n",
    "for i in df.columns.tolist():\n",
    "    if ('td') in i:\n",
    "        vpass.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0.38476426 0.3365185  0.27871724]\n"
     ]
    }
   ],
   "source": [
    "abcde= numPCA(x_wrte,vpass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0.35699219 0.28955011 0.16288295 0.0888593  0.05076722]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC0</td>\n",
       "      <td>l_rush1st17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC1</td>\n",
       "      <td>off_passydsg17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC2</td>\n",
       "      <td>l_gp17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC3</td>\n",
       "      <td>l_actual17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PC4</td>\n",
       "      <td>l_actual17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0               1\n",
       "0  PC0     l_rush1st17\n",
       "1  PC1  off_passydsg17\n",
       "2  PC2          l_gp17\n",
       "3  PC3      l_actual17\n",
       "4  PC4      l_actual17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPCA(x_qb,vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[0.4072918  0.2194014  0.11510606 0.08356412 0.05315177 0.03926797]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC0</td>\n",
       "      <td>l_points17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC1</td>\n",
       "      <td>l_passtd17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC2</td>\n",
       "      <td>off_passydsg17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC3</td>\n",
       "      <td>l_fumble17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PC4</td>\n",
       "      <td>off_runydsg17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PC5</td>\n",
       "      <td>off_passydsg17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0               1\n",
       "0  PC0      l_points17\n",
       "1  PC1      l_passtd17\n",
       "2  PC2  off_passydsg17\n",
       "3  PC3      l_fumble17\n",
       "4  PC4   off_runydsg17\n",
       "5  PC5  off_passydsg17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPCA(x_rb,vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrte = ['l_points17','l_rushyds17','l_returntd17','l_passint17','l_passyds17','l_fumble17','l_gp17','l_rushtd17','l_rectd17','l_actual17','l_returntd17']\n",
    "qb = ['l_rushyds17','l_passyds17','l_gp17','l_actual17','l_fumble17','l_passint17','l_gp17']\n",
    "rb = ['l_points17','l_passtd17','l_rushyds17','l_fumble17','l_gp17','l_rectd17','l_returntd17','l_fumble17','l_rushtd17']\n",
    "x_wrte = x_wrte[wrte]\n",
    "x_qb = x_qb[qb]\n",
    "x_rb = x_rb[rb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 11) (56, 1)\n",
      "(19, 11) (19, 1)\n",
      "(21, 9) (21, 1)\n",
      "(8, 9) (8, 1)\n",
      "(6, 7) (6, 1)\n",
      "(3, 7) (3, 1)\n"
     ]
    }
   ],
   "source": [
    "#SPLIT\n",
    "\n",
    "x_wrte_train, x_wrte_test, y_wrte_train, y_wrte_test = train_test_split(x_wrte, y_wrte, test_size=0.25, random_state=13)\n",
    "print (x_wrte_train.shape, y_wrte_train.shape)\n",
    "print (x_wrte_test.shape, y_wrte_test.shape)\n",
    "\n",
    "x_rb_train, x_rb_test, y_rb_train, y_rb_test = train_test_split(x_rb, y_rb, test_size=0.25, random_state=13)\n",
    "print (x_rb_train.shape, y_rb_train.shape)\n",
    "print (x_rb_test.shape, y_rb_test.shape)\n",
    "\n",
    "x_qb_train, x_qb_test, y_qb_train, y_qb_test = train_test_split(x_qb, y_qb, test_size=0.25, random_state=13)\n",
    "print (x_qb_train.shape, y_qb_train.shape)\n",
    "print (x_qb_test.shape, y_qb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wr and te players\n",
      "\n",
      "cross val for test set\n",
      "lin score -4.580696142628454\n",
      "MSE for test set\n",
      "MSE: lin  3465.491399510602\n",
      "Equation:\n",
      "1.08l_points17 + 42.64l_rushyds17 + 37.01l_returntd17 + 0.1l_passint17 + 42.64l_returntd17\n",
      "\n",
      "\n",
      "qb players\n",
      "cross val for test set\n",
      "lin score -123.73402834264412\n",
      "MSE for test set\n",
      "MSE: lin  63393.91312097042\n",
      "Equation:\n",
      "0.19l_rushyds17 + 3.48l_gp17\n",
      "\n",
      "\n",
      "rb players\n",
      "cross val for test set\n",
      "lin score -15.417837835545626\n",
      "MSE for test set\n",
      "MSE: lin  15637.77651966461\n",
      "Equation:\n",
      "0.31l_points17 + 18.0l_passtd17 + 39.41l_rushyds17 + 340.04l_fumble17 + 18.0l_rushtd17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def lin (x_train, x_test, y_train, y_test,df,df2,vars):\n",
    "    # try both linear and polynomial of different degrees\n",
    "    linear_model = LinearRegression(normalize=True)\n",
    "    lin_1 = linear_model.fit(x_train, y_train)\n",
    "    lin1_predict = lin_1.predict(x_test)\n",
    "    print('cross val for test set')\n",
    "    lin_score=np.mean(cross_val_score(linear_model, df[vars],df2, cv=3))\n",
    "    print(\"lin score\", lin_score)\n",
    "    print('MSE for test set')\n",
    "    print('MSE: lin ', mean_squared_error(lin1_predict, y_test))\n",
    "    \n",
    "    coefs = lin_1.coef_[lin_1.coef_ > .000001]\n",
    "    equation_dict = {}\n",
    "    print(f'Equation:')\n",
    "    for i in range(len(coefs[:-1])):\n",
    "        print(f'{round(coefs[i], 2)}{vars[i]}', end=' + ')\n",
    "        equation_dict[coefs[i]] = vars[i]\n",
    "    print(f'{round(coefs[-1], 2)}{vars[-1]}')\n",
    "    equation_dict[coefs[-1]] = vars[-1]\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"\\nwr and te players\\n\")       \n",
    "lin(x_wrte_train, x_wrte_test, y_wrte_train, y_wrte_test,x_wrte,y_wrte,wrte) \n",
    "print(\"\\n\\nqb players\")       \n",
    "lin(x_qb_train, x_qb_test, y_qb_train, y_qb_test,x_qb,y_qb,qb) \n",
    "print(\"\\n\\nrb players\")       \n",
    "lin(x_rb_train, x_rb_test, y_rb_train, y_rb_test,x_rb,y_rb,rb) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
